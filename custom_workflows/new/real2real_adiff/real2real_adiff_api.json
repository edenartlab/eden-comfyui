{
  "207": {
    "inputs": {
      "add_noise": "enable",
      "noise_seed": 261986541818834,
      "steps": 20,
      "cfg": 8,
      "sampler_name": "euler_ancestral",
      "scheduler": "normal",
      "start_at_step": 0,
      "end_at_step": 20,
      "return_with_leftover_noise": "disable",
      "preview_method": "auto",
      "vae_decode": "true",
      "model": [
        "547",
        0
      ],
      "positive": [
        "468",
        0
      ],
      "negative": [
        "468",
        1
      ],
      "latent_image": [
        "464",
        0
      ],
      "optional_vae": [
        "461",
        2
      ]
    },
    "class_type": "KSampler Adv. (Efficient)",
    "_meta": {
      "title": "KSampler Adv. (Efficient), CN sampler"
    }
  },
  "281": {
    "inputs": {
      "frame_rate": 16,
      "loop_count": 0,
      "filename_prefix": "steerable-motion/AD_",
      "format": "video/h264-mp4",
      "pix_fmt": "yuv420p",
      "crf": 20,
      "save_metadata": true,
      "pingpong": false,
      "save_output": true,
      "images": [
        "633",
        0
      ]
    },
    "class_type": "VHS_VideoCombine",
    "_meta": {
      "title": "Video Combine 🎥🅥🅗🅢"
    }
  },
  "342": {
    "inputs": {
      "context_length": 16,
      "context_stride": 1,
      "context_overlap": 4,
      "context_schedule": "uniform",
      "closed_loop": true,
      "fuse_method": "flat",
      "use_on_equal_length": false,
      "start_percent": 0,
      "guarantee_steps": 1
    },
    "class_type": "ADE_AnimateDiffUniformContextOptions",
    "_meta": {
      "title": "Context Options◆Looped Uniform 🎭🅐🅓"
    }
  },
  "369": {
    "inputs": {
      "ipadapter_file": "ip-adapter-plus_sd15.safetensors"
    },
    "class_type": "IPAdapterModelLoader",
    "_meta": {
      "title": "IPAdapter Model Loader"
    }
  },
  "370": {
    "inputs": {
      "clip_name": "CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Load CLIP Vision"
    }
  },
  "389": {
    "inputs": {
      "images": [
        "604",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "436": {
    "inputs": {
      "images": [
        "624",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "461": {
    "inputs": {
      "ckpt_name": "juggernaut_reborn.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "464": {
    "inputs": {
      "width": [
        "604",
        1
      ],
      "height": [
        "604",
        2
      ],
      "batch_size": [
        "624",
        5
      ]
    },
    "class_type": "ADE_EmptyLatentImageLarge",
    "_meta": {
      "title": "Empty Latent Image (Big Batch) 🎭🅐🅓"
    }
  },
  "467": {
    "inputs": {
      "sparsectrl_name": "v3_sd15_sparsectrl_rgb.ckpt",
      "use_motion": true,
      "motion_strength": 1.04,
      "motion_scale": 1,
      "sparse_method": [
        "624",
        4
      ]
    },
    "class_type": "ACN_SparseCtrlLoaderAdvanced",
    "_meta": {
      "title": "Load SparseCtrl Model 🛂🅐🅒🅝"
    }
  },
  "468": {
    "inputs": {
      "strength": 0.8,
      "start_percent": 0,
      "end_percent": 0.7000000000000001,
      "positive": [
        "624",
        1
      ],
      "negative": [
        "624",
        2
      ],
      "control_net": [
        "467",
        0
      ],
      "image": [
        "469",
        0
      ]
    },
    "class_type": "ACN_AdvancedControlNetApply",
    "_meta": {
      "title": "Apply Advanced ControlNet 🛂🅐🅒🅝"
    }
  },
  "469": {
    "inputs": {
      "image": [
        "604",
        0
      ],
      "vae": [
        "461",
        2
      ],
      "latent_size": [
        "464",
        0
      ]
    },
    "class_type": "ACN_SparseCtrlRGBPreprocessor",
    "_meta": {
      "title": "RGB SparseCtrl 🛂🅐🅒🅝"
    }
  },
  "536": {
    "inputs": {
      "lora_name": "WAS26.safetensors",
      "strength": 0.75
    },
    "class_type": "ADE_AnimateDiffLoRALoader",
    "_meta": {
      "title": "Load AnimateDiff LoRA 🎭🅐🅓"
    }
  },
  "541": {
    "inputs": {
      "text": "\"4\": \"\", \"36\": \"\", \"68\": \"\"",
      "max_frames": 200,
      "current_frame": 0,
      "print_output": false,
      "pre_text": "high quality, sharp details, stunning, 4k, UHD",
      "app_text": "",
      "pw_a": 0,
      "pw_b": 0,
      "pw_c": 0,
      "pw_d": 0,
      "clip": [
        "638",
        1
      ]
    },
    "class_type": "PromptSchedule",
    "_meta": {
      "title": "Positive Prompt"
    }
  },
  "543": {
    "inputs": {
      "text": "\"4\": \"\", \"36\": \"\", \"68\": \"\"",
      "max_frames": 200,
      "current_frame": 0,
      "print_output": false,
      "pre_text": "watermark, nude, naked, text, blurry, jpeg artifacts, low-resolution, bad quality, ugly, distorted, padding",
      "app_text": "",
      "pw_a": 0,
      "pw_b": 0,
      "pw_c": 0,
      "pw_d": 0,
      "clip": [
        "638",
        1
      ]
    },
    "class_type": "PromptSchedule",
    "_meta": {
      "title": "Negative Prompt"
    }
  },
  "544": {
    "inputs": {
      "float_val": [
        "548",
        0
      ]
    },
    "class_type": "ADE_MultivalDynamic",
    "_meta": {
      "title": "Multival Dynamic 🎭🅐🅓"
    }
  },
  "545": {
    "inputs": {
      "start_percent": 0,
      "end_percent": 1,
      "motion_model": [
        "546",
        0
      ],
      "motion_lora": [
        "536",
        0
      ],
      "scale_multival": [
        "544",
        0
      ]
    },
    "class_type": "ADE_ApplyAnimateDiffModel",
    "_meta": {
      "title": "Apply AnimateDiff Model (Adv.) 🎭🅐🅓②"
    }
  },
  "546": {
    "inputs": {
      "model_name": "v3_sd15_mm.ckpt"
    },
    "class_type": "ADE_LoadAnimateDiffModel",
    "_meta": {
      "title": "Load AnimateDiff Model 🎭🅐🅓②"
    }
  },
  "547": {
    "inputs": {
      "beta_schedule": "sqrt_linear (AnimateDiff)",
      "model": [
        "624",
        3
      ],
      "m_models": [
        "545",
        0
      ],
      "context_options": [
        "342",
        0
      ]
    },
    "class_type": "ADE_UseEvolvedSampling",
    "_meta": {
      "title": "Use Evolved Sampling 🎭🅐🅓②"
    }
  },
  "548": {
    "inputs": {
      "text": "0:(1.15)",
      "print_output": true,
      "num_latents": [
        "464",
        0
      ]
    },
    "class_type": "BatchValueScheduleLatentInput",
    "_meta": {
      "title": "Batch Value Schedule (Latent Input) 📅🅕🅝"
    }
  },
  "584": {
    "inputs": {
      "Value": 512
    },
    "class_type": "Integer",
    "_meta": {
      "title": "Resolution"
    }
  },
  "593": {
    "inputs": {
      "ipa_starts_at": 0,
      "ipa_ends_at": 0.3,
      "ipa_weight_type": "ease in-out",
      "ipa_weight": 1,
      "ipa_embeds_scaling": "V only",
      "ipa_noise_strength": 0,
      "use_image_for_noise": false,
      "type_of_noise": "fade",
      "noise_blur": 0
    },
    "class_type": "IpaConfiguration",
    "_meta": {
      "title": "IPA Configuration  🎞️🅢🅜"
    }
  },
  "594": {
    "inputs": {
      "ipa_starts_at": 0.3,
      "ipa_ends_at": 0.8,
      "ipa_weight_type": "linear",
      "ipa_weight": 1,
      "ipa_embeds_scaling": "V only",
      "ipa_noise_strength": 0,
      "use_image_for_noise": false,
      "type_of_noise": "fade",
      "noise_blur": 0
    },
    "class_type": "IpaConfiguration",
    "_meta": {
      "title": "IPA Configuration  🎞️🅢🅜"
    }
  },
  "604": {
    "inputs": {
      "width": [
        "584",
        0
      ],
      "height": [
        "584",
        0
      ],
      "interpolation": "nearest",
      "keep_proportion": true,
      "condition": "always",
      "multiple_of": 32,
      "image": [
        "636",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "🔧 Image Resize"
    }
  },
  "624": {
    "inputs": {
      "type_of_frame_distribution": "linear",
      "linear_frame_distribution_value": 24,
      "dynamic_frame_distribution_values": "",
      "type_of_key_frame_influence": "linear",
      "linear_key_frame_influence_value": "0.8",
      "dynamic_key_frame_influence_values": "",
      "type_of_strength_distribution": "linear",
      "linear_strength_value": "(0.0,1.0)",
      "dynamic_strength_values": "",
      "buffer": 3,
      "high_detail_mode": true,
      "positive": [
        "541",
        0
      ],
      "negative": [
        "543",
        1
      ],
      "images": [
        "604",
        0
      ],
      "model": [
        "638",
        0
      ],
      "ipadapter": [
        "369",
        0
      ],
      "clip_vision": [
        "370",
        0
      ],
      "base_ipa_advanced_settings": [
        "593",
        0
      ],
      "detail_ipa_advanced_settings": [
        "594",
        0
      ]
    },
    "class_type": "BatchCreativeInterpolation",
    "_meta": {
      "title": "Batch Creative Interpolation 🎞️🅢🅜"
    }
  },
  "633": {
    "inputs": {
      "ckpt_name": "rife47.pth",
      "clear_cache_after_n_frames": 10,
      "multiplier": 2,
      "fast_mode": true,
      "ensemble": true,
      "scale_factor": 1,
      "frames": [
        "635",
        0
      ]
    },
    "class_type": "RIFE VFI",
    "_meta": {
      "title": "RIFE VFI (recommend rife47 and rife49)"
    }
  },
  "634": {
    "inputs": {
      "model_name": "RealESRGAN_x2plus.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "635": {
    "inputs": {
      "upscale_model": [
        "634",
        0
      ],
      "image": [
        "207",
        5
      ]
    },
    "class_type": "ImageUpscaleWithModel",
    "_meta": {
      "title": "Upscale Image (using Model)"
    }
  },
  "636": {
    "inputs": {
      "folder": "/home/rednax/SSD2TB/stored_CLIP_results/AAA_init_imgs/01_remove/01",
      "n_images": 3,
      "seed": 1,
      "sort": true
    },
    "class_type": "LoadRandomImage",
    "_meta": {
      "title": "LoadRandomImage"
    }
  },
  "638": {
    "inputs": {
      "lora_name": "v3_sd15_adapter.ckpt",
      "strength_model": 0.7000000000000001,
      "strength_clip": 0.7000000000000001,
      "model": [
        "461",
        0
      ],
      "clip": [
        "461",
        1
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load LoRA"
    }
  }
}