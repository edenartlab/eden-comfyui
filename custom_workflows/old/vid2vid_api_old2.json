{
  "4": {
    "inputs": {
      "ckpt_name": "juggernaut_reborn.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "6": {
    "inputs": {
      "text": [
        "202",
        0
      ],
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "7": {
    "inputs": {
      "text": "shutterstock watermark, nude, naked, text, blurry, jpeg artifacts, low-resolution, bad quality, ugly, distorted",
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "8": {
    "inputs": {
      "samples": [
        "58",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "11": {
    "inputs": {
      "model_name": "v3_sd15_mm.ckpt",
      "beta_schedule": "sqrt_linear (AnimateDiff)",
      "motion_scale": 1,
      "apply_v2_models_properly": true,
      "model": [
        "91",
        0
      ],
      "context_options": [
        "66",
        0
      ]
    },
    "class_type": "ADE_AnimateDiffLoaderWithContext",
    "_meta": {
      "title": "AnimateDiff Loader üé≠üÖêüÖì"
    }
  },
  "24": {
    "inputs": {
      "ipadapter_file": "ip-adapter-plus_sd15.safetensors"
    },
    "class_type": "IPAdapterModelLoader",
    "_meta": {
      "title": "Load IPAdapter Model"
    }
  },
  "25": {
    "inputs": {
      "clip_name": "CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Load CLIP Vision"
    }
  },
  "54": {
    "inputs": {
      "image": "strawberries2.jpeg",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "55": {
    "inputs": {
      "interpolation": "LANCZOS",
      "crop_position": "bottom",
      "sharpening": 0,
      "image": [
        "54",
        0
      ]
    },
    "class_type": "PrepImageForClipVision",
    "_meta": {
      "title": "Prepare Image For Clip Vision"
    }
  },
  "58": {
    "inputs": {
      "seed": 237,
      "steps": 25,
      "cfg": 10,
      "sampler_name": "dpmpp_2m_sde",
      "scheduler": "exponential",
      "denoise": 1,
      "model": [
        "276",
        0
      ],
      "positive": [
        "132",
        0
      ],
      "negative": [
        "132",
        1
      ],
      "latent_image": [
        "253",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "59": {
    "inputs": {
      "ckpt_name": "rife47.pth",
      "clear_cache_after_n_frames": 24,
      "multiplier": 3,
      "fast_mode": true,
      "ensemble": true,
      "scale_factor": 1,
      "cache_in_fp16": true,
      "frames": [
        "62",
        0
      ]
    },
    "class_type": "RIFE VFI",
    "_meta": {
      "title": "RIFE VFI (recommend rife47 and rife49)"
    }
  },
  "62": {
    "inputs": {
      "upscale_model": [
        "63",
        0
      ],
      "image": [
        "222",
        0
      ]
    },
    "class_type": "ImageUpscaleWithModel",
    "_meta": {
      "title": "Upscale Image (using Model)"
    }
  },
  "63": {
    "inputs": {
      "model_name": "RealESRGAN_x2plus.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "66": {
    "inputs": {
      "context_length": 16,
      "context_stride": 1,
      "context_overlap": 4,
      "context_schedule": "uniform",
      "closed_loop": false
    },
    "class_type": "ADE_AnimateDiffUniformContextOptions",
    "_meta": {
      "title": "Uniform Context Options üé≠üÖêüÖì"
    }
  },
  "91": {
    "inputs": {
      "lora_name": "v3_sd15_adapter.ckpt",
      "strength_model": 0.8,
      "model": [
        "4",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  },
  "95": {
    "inputs": {
      "pixels": [
        "221",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "132": {
    "inputs": {
      "strength": 0.8,
      "start_percent": 0,
      "end_percent": 0.75,
      "positive": [
        "342",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "control_net": [
        "133",
        0
      ],
      "image": [
        "360",
        0
      ]
    },
    "class_type": "ACN_AdvancedControlNetApply",
    "_meta": {
      "title": "Apply Advanced ControlNet üõÇüÖêüÖíüÖù"
    }
  },
  "133": {
    "inputs": {
      "control_net_name": "v3_sd15_sparsectrl_scribble.ckpt"
    },
    "class_type": "ControlNetLoaderAdvanced",
    "_meta": {
      "title": "Load Advanced ControlNet Model üõÇüÖêüÖíüÖù"
    }
  },
  "169": {
    "inputs": {
      "coarse": "disable",
      "resolution": 1024,
      "image": [
        "221",
        0
      ]
    },
    "class_type": "LineArtPreprocessor",
    "_meta": {
      "title": "Realistic Lineart"
    }
  },
  "173": {
    "inputs": {
      "x": 0,
      "y": 0,
      "operation": "or",
      "destination": [
        "316",
        0
      ],
      "source": [
        "320",
        0
      ]
    },
    "class_type": "MaskComposite",
    "_meta": {
      "title": "MaskComposite"
    }
  },
  "177": {
    "inputs": {
      "channel": "red",
      "image": [
        "268",
        0
      ]
    },
    "class_type": "ImageToMask",
    "_meta": {
      "title": "Convert Image to Mask"
    }
  },
  "178": {
    "inputs": {
      "channel": "red",
      "image": [
        "169",
        0
      ]
    },
    "class_type": "ImageToMask",
    "_meta": {
      "title": "Convert Image to Mask"
    }
  },
  "180": {
    "inputs": {
      "mask": [
        "173",
        0
      ]
    },
    "class_type": "MaskToImage",
    "_meta": {
      "title": "Convert Mask to Image"
    }
  },
  "202": {
    "inputs": {
      "prompt1": [
        "246",
        0
      ],
      "separator": ", ",
      "prompt2": "high quality texture, sharp details, 4k"
    },
    "class_type": "SeargePromptCombiner",
    "_meta": {
      "title": "Prompt combiner"
    }
  },
  "221": {
    "inputs": {
      "pad_fraction": 0,
      "pad_location": "bottom",
      "image": [
        "240",
        0
      ]
    },
    "class_type": "IMG_padder",
    "_meta": {
      "title": "IMG_Padder"
    }
  },
  "222": {
    "inputs": {
      "unpad_fraction": 0,
      "unpad_location": "bottom",
      "image": [
        "8",
        0
      ]
    },
    "class_type": "IMG_unpadder",
    "_meta": {
      "title": "IMG_Unpadder"
    }
  },
  "237": {
    "inputs": {
      "frame_rate": 24,
      "loop_count": 0,
      "filename_prefix": "vid2vid",
      "format": "video/h264-mp4",
      "pix_fmt": "yuv420p",
      "crf": 23,
      "save_metadata": true,
      "pingpong": false,
      "save_output": true,
      "images": [
        "59",
        0
      ]
    },
    "class_type": "VHS_VideoCombine",
    "_meta": {
      "title": "Video Combine üé•üÖ•üÖóüÖ¢"
    }
  },
  "238": {
    "inputs": {
      "video": "waking_life.mp4",
      "force_rate": 8,
      "force_size": "Disabled",
      "custom_width": 512,
      "custom_height": 512,
      "frame_load_cap": 52,
      "skip_first_frames": 0,
      "select_every_nth": 1
    },
    "class_type": "VHS_LoadVideo",
    "_meta": {
      "title": "Load Video (Upload) üé•üÖ•üÖóüÖ¢"
    }
  },
  "240": {
    "inputs": {
      "width": 1024,
      "height": 1024,
      "interpolation": "lanczos",
      "keep_proportion": true,
      "condition": "always",
      "image": [
        "238",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "üîß Image Resize"
    }
  },
  "246": {
    "inputs": {
      "mode": "fast",
      "keep_model_alive": true,
      "prepend_blip_caption": false,
      "save_prompt_to_txt_file": "clip_interrogator_prompt.txt",
      "image": [
        "304",
        0
      ]
    },
    "class_type": "CLIP_Interrogator",
    "_meta": {
      "title": "CLIP_Interrogator"
    }
  },
  "253": {
    "inputs": {
      "output_type": "float16",
      "verbose": false,
      "latent": [
        "95",
        0
      ]
    },
    "class_type": "LatentTypeConversion",
    "_meta": {
      "title": "LatentTypeConversion"
    }
  },
  "268": {
    "inputs": {
      "safe": "enable",
      "resolution": 1024,
      "image": [
        "221",
        0
      ]
    },
    "class_type": "FakeScribblePreprocessor",
    "_meta": {
      "title": "Fake Scribble Lines (aka scribble_hed)"
    }
  },
  "275": {
    "inputs": {
      "ipadapter_plus": true,
      "noise": 0.25,
      "weight_1": 1,
      "weight_2": 1,
      "weight_3": 1,
      "weight_4": 1,
      "clip_vision": [
        "25",
        0
      ],
      "image_1": [
        "303",
        0
      ],
      "image_2": [
        "302",
        0
      ],
      "image_3": [
        "301",
        0
      ],
      "image_4": [
        "55",
        0
      ]
    },
    "class_type": "IPAdapterEncoder",
    "_meta": {
      "title": "Encode IPAdapter Image"
    }
  },
  "276": {
    "inputs": {
      "weight": 0.65,
      "weight_type": "original",
      "start_at": 0,
      "end_at": 0.5,
      "unfold_batch": false,
      "ipadapter": [
        "24",
        0
      ],
      "embeds": [
        "306",
        0
      ],
      "model": [
        "11",
        0
      ]
    },
    "class_type": "IPAdapterApplyEncoded",
    "_meta": {
      "title": "Apply IPAdapter from Encoded"
    }
  },
  "301": {
    "inputs": {
      "interpolation": "LANCZOS",
      "crop_position": "top",
      "sharpening": 0,
      "image": [
        "54",
        0
      ]
    },
    "class_type": "PrepImageForClipVision",
    "_meta": {
      "title": "Prepare Image For Clip Vision"
    }
  },
  "302": {
    "inputs": {
      "interpolation": "LANCZOS",
      "crop_position": "right",
      "sharpening": 0,
      "image": [
        "54",
        0
      ]
    },
    "class_type": "PrepImageForClipVision",
    "_meta": {
      "title": "Prepare Image For Clip Vision"
    }
  },
  "303": {
    "inputs": {
      "interpolation": "LANCZOS",
      "crop_position": "left",
      "sharpening": 0,
      "image": [
        "54",
        0
      ]
    },
    "class_type": "PrepImageForClipVision",
    "_meta": {
      "title": "Prepare Image For Clip Vision"
    }
  },
  "304": {
    "inputs": {
      "interpolation": "LANCZOS",
      "crop_position": "pad",
      "sharpening": 0,
      "image": [
        "54",
        0
      ]
    },
    "class_type": "PrepImageForClipVision",
    "_meta": {
      "title": "Prepare Image For Clip Vision"
    }
  },
  "306": {
    "inputs": {
      "embed1": [
        "309",
        0
      ],
      "embed2": [
        "275",
        0
      ]
    },
    "class_type": "IPAdapterBatchEmbeds",
    "_meta": {
      "title": "IPAdapter Batch Embeds"
    }
  },
  "308": {
    "inputs": {
      "interpolation": "LANCZOS",
      "crop_position": "right",
      "sharpening": 0,
      "image": [
        "341",
        0
      ]
    },
    "class_type": "PrepImageForClipVision",
    "_meta": {
      "title": "Prepare Image For Clip Vision"
    }
  },
  "309": {
    "inputs": {
      "ipadapter_plus": true,
      "noise": 0.25,
      "weight_1": 1,
      "weight_2": 1,
      "weight_3": 1,
      "weight_4": 1,
      "clip_vision": [
        "25",
        0
      ],
      "image_1": [
        "312",
        0
      ],
      "image_2": [
        "311",
        0
      ],
      "image_3": [
        "310",
        0
      ],
      "image_4": [
        "308",
        0
      ]
    },
    "class_type": "IPAdapterEncoder",
    "_meta": {
      "title": "Encode IPAdapter Image"
    }
  },
  "310": {
    "inputs": {
      "interpolation": "LANCZOS",
      "crop_position": "left",
      "sharpening": 0,
      "image": [
        "341",
        0
      ]
    },
    "class_type": "PrepImageForClipVision",
    "_meta": {
      "title": "Prepare Image For Clip Vision"
    }
  },
  "311": {
    "inputs": {
      "interpolation": "LANCZOS",
      "crop_position": "bottom",
      "sharpening": 0,
      "image": [
        "341",
        0
      ]
    },
    "class_type": "PrepImageForClipVision",
    "_meta": {
      "title": "Prepare Image For Clip Vision"
    }
  },
  "312": {
    "inputs": {
      "interpolation": "LANCZOS",
      "crop_position": "top",
      "sharpening": 0,
      "image": [
        "341",
        0
      ]
    },
    "class_type": "PrepImageForClipVision",
    "_meta": {
      "title": "Prepare Image For Clip Vision"
    }
  },
  "316": {
    "inputs": {
      "expand": 2,
      "tapered_corners": true,
      "mask": [
        "178",
        0
      ]
    },
    "class_type": "GrowMask",
    "_meta": {
      "title": "GrowMask"
    }
  },
  "320": {
    "inputs": {
      "expand": -3,
      "tapered_corners": true,
      "mask": [
        "177",
        0
      ]
    },
    "class_type": "GrowMask",
    "_meta": {
      "title": "GrowMask"
    }
  },
  "334": {
    "inputs": {
      "mask": [
        "320",
        0
      ]
    },
    "class_type": "MaskToImage",
    "_meta": {
      "title": "Convert Mask to Image"
    }
  },
  "341": {
    "inputs": {
      "image": "strawberry.jpeg",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "342": {
    "inputs": {
      "conditioning_to_strength": 0.5,
      "conditioning_to": [
        "344",
        0
      ],
      "conditioning_from": [
        "6",
        0
      ]
    },
    "class_type": "ConditioningAverage",
    "_meta": {
      "title": "ConditioningAverage"
    }
  },
  "343": {
    "inputs": {
      "mode": "fast",
      "keep_model_alive": true,
      "prepend_blip_caption": false,
      "save_prompt_to_txt_file": "clip_interrogator_prompt.txt",
      "image": [
        "349",
        0
      ]
    },
    "class_type": "CLIP_Interrogator",
    "_meta": {
      "title": "CLIP_Interrogator"
    }
  },
  "344": {
    "inputs": {
      "text": [
        "345",
        0
      ],
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "345": {
    "inputs": {
      "prompt1": [
        "343",
        0
      ],
      "separator": ", ",
      "prompt2": "high quality texture, sharp details, 4k"
    },
    "class_type": "SeargePromptCombiner",
    "_meta": {
      "title": "Prompt combiner"
    }
  },
  "349": {
    "inputs": {
      "interpolation": "LANCZOS",
      "crop_position": "pad",
      "sharpening": 0,
      "image": [
        "341",
        0
      ]
    },
    "class_type": "PrepImageForClipVision",
    "_meta": {
      "title": "Prepare Image For Clip Vision"
    }
  },
  "354": {
    "inputs": {
      "batch_index_from": 0,
      "batch_index_to_excl": 10,
      "strength_from": 0,
      "strength_to": 0.8,
      "interpolation": "linear",
      "print_keyframes": true
    },
    "class_type": "LatentKeyframeTiming",
    "_meta": {
      "title": "Latent Keyframe Interpolation üõÇüÖêüÖíüÖù"
    }
  },
  "356": {
    "inputs": {
      "batch_index_from": 10,
      "batch_index_to_excl": 30,
      "strength_from": 0.8,
      "strength_to": 0.8,
      "interpolation": "linear",
      "print_keyframes": true,
      "prev_latent_kf": [
        "354",
        0
      ]
    },
    "class_type": "LatentKeyframeTiming",
    "_meta": {
      "title": "Latent Keyframe Interpolation üõÇüÖêüÖíüÖù"
    }
  },
  "358": {
    "inputs": {
      "batch_index_from": 30,
      "batch_index_to_excl": 40,
      "strength_from": 0.8,
      "strength_to": 0,
      "interpolation": "linear",
      "print_keyframes": true,
      "prev_latent_kf": [
        "356",
        0
      ]
    },
    "class_type": "LatentKeyframeTiming",
    "_meta": {
      "title": "Latent Keyframe Interpolation üõÇüÖêüÖíüÖù"
    }
  },
  "360": {
    "inputs": {
      "ANY": [
        "362",
        0
      ],
      "IF_TRUE": [
        "180",
        0
      ],
      "IF_FALSE": [
        "334",
        0
      ]
    },
    "class_type": "If ANY execute A else B",
    "_meta": {
      "title": "If"
    }
  },
  "361": {
    "inputs": {
      "value": "coarse"
    },
    "class_type": "String",
    "_meta": {
      "title": "ControlMethod (fine/coarse)"
    }
  },
  "362": {
    "inputs": {
      "comparison": "a == b",
      "a": [
        "361",
        0
      ],
      "b": [
        "363",
        0
      ]
    },
    "class_type": "Compare",
    "_meta": {
      "title": "Compare"
    }
  },
  "363": {
    "inputs": {
      "value": "fine"
    },
    "class_type": "String",
    "_meta": {
      "title": "String"
    }
  }
}